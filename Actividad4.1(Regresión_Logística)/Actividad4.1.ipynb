{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7468e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4593b",
   "metadata": {},
   "source": [
    "### Acciones de preprocesamiento necesarias: Nulos y Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb460e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>room_type</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>property_type</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41339</td>\n",
       "      <td>...</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55111</td>\n",
       "      <td>...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>73828</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.87</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>87873</td>\n",
       "      <td>...</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>94701</td>\n",
       "      <td>...</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>96394</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100521</td>\n",
       "      <td>...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>104045</td>\n",
       "      <td>...</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>105347</td>\n",
       "      <td>...</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108153</td>\n",
       "      <td>...</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_response_time  neighbourhood  host_is_superhost  room_type  \\\n",
       "0                   3              1                  1          1   \n",
       "1                   3              1                  1          1   \n",
       "2                   3              1                  1          1   \n",
       "3                   1              1                  2          1   \n",
       "4                   1              1                  2          1   \n",
       "5                   1              2                  1          1   \n",
       "6                   1              2                  1          2   \n",
       "7                   1              1                  1          1   \n",
       "8                   1              1                  2          1   \n",
       "9                   2              1                  1          2   \n",
       "\n",
       "   host_has_profile_pic  host_identity_verified  property_type  \\\n",
       "0                     1                       1              1   \n",
       "1                     1                       1              1   \n",
       "2                     1                       1              1   \n",
       "3                     1                       1              1   \n",
       "4                     1                       1              1   \n",
       "5                     1                       1             18   \n",
       "6                     1                       2              3   \n",
       "7                     1                       1              1   \n",
       "8                     1                       1             16   \n",
       "9                     1                       1              8   \n",
       "\n",
       "   has_availability  instant_bookable      id  ...  review_scores_accuracy  \\\n",
       "0                 1                 2   41339  ...                    4.73   \n",
       "1                 1                 2   55111  ...                    4.80   \n",
       "2                 1                 2   73828  ...                    5.00   \n",
       "3                 1                 2   87873  ...                    4.87   \n",
       "4                 1                 2   94701  ...                    4.84   \n",
       "5                 1                 2   96394  ...                    5.00   \n",
       "6                 1                 2  100521  ...                    4.80   \n",
       "7                 1                 1  104045  ...                    4.70   \n",
       "8                 1                 2  105347  ...                    4.96   \n",
       "9                 1                 2  108153  ...                    4.87   \n",
       "\n",
       "   review_scores_cleanliness  review_scores_checkin  \\\n",
       "0                       4.85                   4.88   \n",
       "1                       4.75                   4.90   \n",
       "2                       4.87                   5.00   \n",
       "3                       4.89                   4.97   \n",
       "4                       4.84                   4.94   \n",
       "5                       5.00                   5.00   \n",
       "6                       4.80                   4.90   \n",
       "7                       4.70                   4.86   \n",
       "8                       4.99                   4.96   \n",
       "9                       4.80                   4.87   \n",
       "\n",
       "   review_scores_communication  review_scores_location  review_scores_value  \\\n",
       "0                         4.85                    4.62                 4.69   \n",
       "1                         4.90                    4.79                 4.79   \n",
       "2                         5.00                    4.93                 4.80   \n",
       "3                         4.94                    4.52                 4.81   \n",
       "4                         4.95                    4.85                 4.77   \n",
       "5                         5.00                    5.00                 4.91   \n",
       "6                         4.90                    4.80                 4.70   \n",
       "7                         4.92                    4.27                 4.68   \n",
       "8                         4.94                    4.58                 4.90   \n",
       "9                         4.73                    4.53                 4.73   \n",
       "\n",
       "   calculated_host_listings_count  \\\n",
       "0                             1.0   \n",
       "1                             3.0   \n",
       "2                             3.0   \n",
       "3                             4.0   \n",
       "4                             1.0   \n",
       "5                             1.0   \n",
       "6                             1.0   \n",
       "7                             1.0   \n",
       "8                             1.0   \n",
       "9                             2.0   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                          1.0   \n",
       "1                                          3.0   \n",
       "2                                          3.0   \n",
       "3                                          2.0   \n",
       "4                                          1.0   \n",
       "5                                          1.0   \n",
       "6                                          0.0   \n",
       "7                                          1.0   \n",
       "8                                          1.0   \n",
       "9                                          1.0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  reviews_per_month  \n",
       "0                                           0.0               0.18  \n",
       "1                                           0.0               0.17  \n",
       "2                                           0.0               0.13  \n",
       "3                                           2.0               1.60  \n",
       "4                                           0.0               1.81  \n",
       "5                                           0.0               0.11  \n",
       "6                                           1.0               0.00  \n",
       "7                                           0.0               1.89  \n",
       "8                                           0.0               1.15  \n",
       "9                                           1.0               0.15  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar archivo csv \n",
    "df= pd.read_csv('Porto_clean.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df237b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_response_time                              0\n",
       "neighbourhood                                   0\n",
       "host_is_superhost                               0\n",
       "room_type                                       0\n",
       "host_has_profile_pic                            0\n",
       "host_identity_verified                          0\n",
       "property_type                                   0\n",
       "has_availability                                0\n",
       "instant_bookable                                0\n",
       "id                                              0\n",
       "host_id                                         0\n",
       "host_response_rate                              0\n",
       "host_acceptance_rate                            0\n",
       "host_listings_count                             0\n",
       "host_total_listings_count                       0\n",
       "latitude                                        0\n",
       "longitude                                       0\n",
       "accommodates                                    0\n",
       "bedrooms                                        0\n",
       "beds                                            0\n",
       "price                                           0\n",
       "minimum_nights                                  0\n",
       "maximum_nights                                  0\n",
       "minimum_minimum_nights                          0\n",
       "maximum_minimum_nights                          0\n",
       "minimum_maximum_nights                          0\n",
       "maximum_maximum_nights                          0\n",
       "minimum_nights_avg_ntm                          0\n",
       "maximum_nights_avg_ntm                          0\n",
       "availability_30                                 0\n",
       "availability_60                                 0\n",
       "availability_90                                 0\n",
       "availability_365                                0\n",
       "number_of_reviews                               0\n",
       "number_of_reviews_ltm                           0\n",
       "number_of_reviews_l30d                          0\n",
       "availability_eoy                                0\n",
       "number_of_reviews_ly                            0\n",
       "estimated_occupancy_l365d                       0\n",
       "estimated_revenue_l365d                         0\n",
       "review_scores_rating                            0\n",
       "review_scores_accuracy                          0\n",
       "review_scores_cleanliness                       0\n",
       "review_scores_checkin                           0\n",
       "review_scores_communication                     0\n",
       "review_scores_location                          0\n",
       "review_scores_value                             0\n",
       "calculated_host_listings_count                  0\n",
       "calculated_host_listings_count_entire_homes     0\n",
       "calculated_host_listings_count_private_rooms    0\n",
       "reviews_per_month                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificamos los valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3241153",
   "metadata": {},
   "source": [
    "### Analizar 10 casos de correlación logística que existe entre diferentes variables de nuestra base de datos, aplicando la herramienta de “Regresión Logística”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331a206",
   "metadata": {},
   "source": [
    "#### Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5272168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['beds', 'bedrooms', 'accommodates']]\n",
    "Var_Dep = df['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d85b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[2794   31]\n",
      " [1455   28]]\n",
      "Precisión del modelo:\n",
      "0.6575664862320546\n",
      "Exactitud del modelo:\n",
      "0.6550603528319405\n",
      "Sensibilidad del modelo:\n",
      "0.9890265486725663\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a4903",
   "metadata": {},
   "source": [
    "#### Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5055d7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['beds', 'bedrooms', 'accommodates']]\n",
    "Var_Dep = df['has_availability']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f640f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4274    0]\n",
      " [  34    0]]\n",
      "Precisión del modelo:\n",
      "0.9921077065923862\n",
      "Exactitud del modelo:\n",
      "0.9921077065923862\n",
      "Sensibilidad del modelo:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5b5ca",
   "metadata": {},
   "source": [
    "#### Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b81389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 2, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['price', 'property_type', 'host_identity_verified']]\n",
    "Var_Dep = df['instant_bookable']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0314fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[2652  168]\n",
      " [1223  265]]\n",
      "Precisión del modelo:\n",
      "0.6843870967741935\n",
      "Exactitud del modelo:\n",
      "0.6771123491179202\n",
      "Sensibilidad del modelo:\n",
      "0.9404255319148936\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b197f5",
   "metadata": {},
   "source": [
    "#### Modelo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af4785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['host_is_superhost', 'bedrooms', 'accommodates']]\n",
    "Var_Dep = df['host_response_time']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888bff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[3885    0    0    0]\n",
      " [ 238    0    0    0]\n",
      " [ 129    0    0    0]\n",
      " [  56    0    0    0]]\n",
      "Precisión del modelo:\n",
      "0.22545264623955433\n",
      "Exactitud del modelo:\n",
      "0.9018105849582173\n",
      "Sensibilidad del modelo:\n",
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='macro')\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb32c5",
   "metadata": {},
   "source": [
    "#### Modelo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d6a6bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['availability_365', 'host_total_listings_count', 'estimated_occupancy_l365d']]\n",
    "Var_Dep = df['has_availability']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd8384b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4281    0]\n",
      " [  27    0]]\n",
      "Precisión del modelo:\n",
      "0.9937325905292479\n",
      "Exactitud del modelo:\n",
      "0.9937325905292479\n",
      "Sensibilidad del modelo:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ef515",
   "metadata": {},
   "source": [
    "#### Modelo 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0de9fbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 255,  12, ...,  54,   0,  18], shape=(4308,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['number_of_reviews_ltm', 'availability_365', 'review_scores_location']]\n",
    "Var_Dep = df['estimated_occupancy_l365d']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50a70285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1092    0    0 ...    0    0    0]\n",
      " [ 292    0    0 ...    0    0    0]\n",
      " [   7    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    1]\n",
      " [   0    0    0 ...    0    0   27]\n",
      " [   0    0    0 ...    0    0  491]]\n",
      "Precisión del modelo:\n",
      "0.024820312605068732\n",
      "Exactitud del modelo:\n",
      "0.3869545032497679\n",
      "Sensibilidad del modelo:\n",
      "0.039183737881438994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='macro')\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4de6d1",
   "metadata": {},
   "source": [
    "#### Modelo 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cff0745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.], shape=(4308,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['review_scores_communication', 'review_scores_value', 'review_scores_checkin']]\n",
    "Var_Dep = df['number_of_reviews']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63b1449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[515   0   0 ...   0   0   0]\n",
      " [ 30 188   0 ...   0   0   0]\n",
      " [ 33  92   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  2   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Precisión del modelo:\n",
      "0.005582563314558595\n",
      "Exactitud del modelo:\n",
      "0.19428969359331477\n",
      "Sensibilidad del modelo:\n",
      "0.010599472769854063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='macro')\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595693de",
   "metadata": {},
   "source": [
    "#### Modelo 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b232bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['host_response_rate', 'host_listings_count', 'review_scores_rating']]\n",
    "Var_Dep = df['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdb96a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[2298  510]\n",
      " [ 879  621]]\n",
      "Precisión del modelo:\n",
      "0.7233238904627006\n",
      "Exactitud del modelo:\n",
      "0.6775766016713092\n",
      "Sensibilidad del modelo:\n",
      "0.8183760683760684\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66634ee",
   "metadata": {},
   "source": [
    "#### Modelo 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af3b4b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['host_response_time', 'host_identity_verified', 'host_acceptance_rate']]\n",
    "Var_Dep = df['host_has_profile_pic']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1decf332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4245    0]\n",
      " [  63    0]]\n",
      "Precisión del modelo:\n",
      "0.9853760445682451\n",
      "Exactitud del modelo:\n",
      "0.9853760445682451\n",
      "Sensibilidad del modelo:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc38a4",
   "metadata": {},
   "source": [
    "#### Modelo 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ea71c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4308,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['price', 'host_identity_verified', 'availability_30']]\n",
    "Var_Dep = df['instant_bookable']\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ccd9866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[2762  121]\n",
      " [1245  180]]\n",
      "Precisión del modelo:\n",
      "0.6892937359620663\n",
      "Exactitud del modelo:\n",
      "0.6829155060352832\n",
      "Sensibilidad del modelo:\n",
      "0.9580298300381547\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef1f967",
   "metadata": {},
   "source": [
    "### Convertir las variables que sean necesarias en variables de tipo  dicotómica con las categorías que se consideren pertinentes, aplicando la herramienta de  “Regresión Logística”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4284c",
   "metadata": {},
   "source": [
    "#### host_response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad2c84a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(1), np.int64(4)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el límite superior y el límite inferior de la columna objetivo\n",
    "Max=df['host_response_time'].max()\n",
    "Min=df['host_response_time'].min()\n",
    "Limites = [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9d09279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9, 2.5, 4.1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos\n",
    "intervalos=np.linspace(0.9, 4.1, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fa9ef9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_response_time\n",
       "Fast response time    13687\n",
       "Slow resposne time      673\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos las categorías\n",
    "categorias= ['Fast response time', 'Slow resposne time']\n",
    "\n",
    "#Ajustar máximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['host_response_time']=pd.cut(x=df['host_response_time'], bins=intervalos, labels=categorias)\n",
    "\n",
    "df['host_response_time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d750b",
   "metadata": {},
   "source": [
    "#### estimated_occupancy_l365d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "748ae408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(255)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el límite superior y el límite inferior de la columna objetivo\n",
    "Max=df['estimated_occupancy_l365d'].max()\n",
    "Min=df['estimated_occupancy_l365d'].min()\n",
    "Limites = [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78e9c28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  , 127.55, 255.1 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos\n",
    "intervalos=np.linspace(0, 255.1, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e3d9c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimated_occupancy_l365d\n",
       "High occupancy    6391\n",
       "Low occupancy     4213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos las categorías\n",
    "categorias= ['High occupancy', 'Low occupancy']\n",
    "\n",
    "#Ajustar máximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['estimated_occupancy_l365d']=pd.cut(x=df['estimated_occupancy_l365d'], bins=intervalos, labels=categorias)\n",
    "\n",
    "df['estimated_occupancy_l365d'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8f8c2",
   "metadata": {},
   "source": [
    "#### number_of_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe7d51c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0), np.float64(211.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el límite superior y el límite inferior de la columna objetivo\n",
    "Max=df['number_of_reviews'].max()\n",
    "Min=df['number_of_reviews'].min()\n",
    "Limites = [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36b8cde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0. , 105.5, 211. ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos\n",
    "intervalos=np.linspace(0, 211, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4d77142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_reviews\n",
       "Low number of reviews     10897\n",
       "High number of reviews     1808\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos las categorías\n",
    "categorias= ['Low number of reviews', 'High number of reviews']\n",
    "\n",
    "#Ajustar máximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['number_of_reviews']=pd.cut(x=df['number_of_reviews'], bins=intervalos, labels=categorias)\n",
    "\n",
    "df['number_of_reviews'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b38127",
   "metadata": {},
   "source": [
    "### Realizar una tabla de todos los coeficientes de precisión, exactitud y sensibilidad obtenidos para cada correlación analizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8b9487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable objetivo</th>\n",
       "      <th>Variables independientes</th>\n",
       "      <th>Coeficiente de precisión</th>\n",
       "      <th>Coeficiente de exactitud</th>\n",
       "      <th>Coeficiente de sensibilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_is_superhost</td>\n",
       "      <td>beds, bedrooms, accommodates</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has_availability</td>\n",
       "      <td>beds, bedrooms, accommodates</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instant_bookable</td>\n",
       "      <td>price, property_type, host_identity_verified</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>host_response_time</td>\n",
       "      <td>host_is_superhost, bedrooms, accommodates</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>has_availability</td>\n",
       "      <td>availability_365, host_total_listings_count, e...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>estimated_occupancy_l365d</td>\n",
       "      <td>number_of_reviews_ltm, availability_365, revie...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>review_scores_communication, review_scores_val...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>host_is_superhost</td>\n",
       "      <td>host_response_rate, host_listings_count, revie...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>host_has_profile_pic</td>\n",
       "      <td>host_response_time, host_identity_verified, ho...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instant_bookable</td>\n",
       "      <td>price, host_identity_verified, availability_30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Variable objetivo  \\\n",
       "0          host_is_superhost   \n",
       "1           has_availability   \n",
       "2           instant_bookable   \n",
       "3         host_response_time   \n",
       "4           has_availability   \n",
       "5  estimated_occupancy_l365d   \n",
       "6          number_of_reviews   \n",
       "7          host_is_superhost   \n",
       "8       host_has_profile_pic   \n",
       "9           instant_bookable   \n",
       "\n",
       "                            Variables independientes  \\\n",
       "0                       beds, bedrooms, accommodates   \n",
       "1                       beds, bedrooms, accommodates   \n",
       "2       price, property_type, host_identity_verified   \n",
       "3          host_is_superhost, bedrooms, accommodates   \n",
       "4  availability_365, host_total_listings_count, e...   \n",
       "5  number_of_reviews_ltm, availability_365, revie...   \n",
       "6  review_scores_communication, review_scores_val...   \n",
       "7  host_response_rate, host_listings_count, revie...   \n",
       "8  host_response_time, host_identity_verified, ho...   \n",
       "9     price, host_identity_verified, availability_30   \n",
       "\n",
       "   Coeficiente de precisión  Coeficiente de exactitud  \\\n",
       "0                      0.66                      0.65   \n",
       "1                      0.99                      0.99   \n",
       "2                      0.68                      0.68   \n",
       "3                      0.22                      0.90   \n",
       "4                      0.99                      0.99   \n",
       "5                      0.02                      0.39   \n",
       "6                      0.01                      0.19   \n",
       "7                      0.72                      0.68   \n",
       "8                      0.98                      0.98   \n",
       "9                      0.69                      0.68   \n",
       "\n",
       "   Coeficiente de sensibilidad  \n",
       "0                         0.99  \n",
       "1                         1.00  \n",
       "2                         0.94  \n",
       "3                         0.25  \n",
       "4                         1.00  \n",
       "5                         0.04  \n",
       "6                         0.01  \n",
       "7                         0.82  \n",
       "8                         1.00  \n",
       "9                         0.96  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generamos una tabla con los coeficientes de cada modelo\n",
    "tabla_coeficientes = {\n",
    "    \"Variable objetivo\": [\n",
    "        'host_is_superhost',\n",
    "        'has_availability',\n",
    "        'instant_bookable',\n",
    "        'host_response_time',\n",
    "        'has_availability',\n",
    "        'estimated_occupancy_l365d',\n",
    "        'number_of_reviews',\n",
    "        'host_is_superhost',\n",
    "        'host_has_profile_pic',\n",
    "        'instant_bookable'\n",
    "    ],\n",
    "    'Variables independientes': [\n",
    "        'beds, bedrooms, accommodates',\n",
    "        'beds, bedrooms, accommodates',\n",
    "        'price, property_type, host_identity_verified',\n",
    "        'host_is_superhost, bedrooms, accommodates',\n",
    "        'availability_365, host_total_listings_count, estimated_occupancy_l365d',\n",
    "        'number_of_reviews_ltm, availability_365, review_scores_location',\n",
    "        'review_scores_communication, review_scores_value, review_scores_checkin',\n",
    "        'host_response_rate, host_listings_count, review_scores_rating',\n",
    "        'host_response_time, host_identity_verified, host_acceptance_rate',\n",
    "        'price, host_identity_verified, availability_30'\n",
    "    ],\n",
    "    'Coeficiente de precisión': [\n",
    "        0.66,\n",
    "        0.99,\n",
    "        0.68,\n",
    "        0.22,\n",
    "        0.99,\n",
    "        0.02,\n",
    "        0.01,\n",
    "        0.72,\n",
    "        0.98,\n",
    "        0.69\n",
    "    ],\n",
    "    'Coeficiente de exactitud': [\n",
    "        0.65,\n",
    "        0.99,\n",
    "        0.68,\n",
    "        0.90,\n",
    "        0.99,\n",
    "        0.39,\n",
    "        0.19,\n",
    "        0.68,\n",
    "        0.98,\n",
    "        0.68\n",
    "    ],\n",
    "    'Coeficiente de sensibilidad': [\n",
    "        0.99,\n",
    "        1,\n",
    "        0.94,\n",
    "        0.25,\n",
    "        1,\n",
    "        0.04,\n",
    "        0.01,\n",
    "        0.82,\n",
    "        1,\n",
    "        0.96\n",
    "    ],\n",
    "}\n",
    "df_coeficientes = pd.DataFrame(tabla_coeficientes)\n",
    "df_coeficientes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
